import { GoogleGenerativeAI } from '@google/generative-ai'
import { NextRequest, NextResponse } from 'next/server'
import { createRouteHandlerClient } from '@supabase/auth-helpers-nextjs'
import { cookies } from 'next/headers'
import { withRateLimit } from '@/lib/rateLimitMiddleware'
import { checkMonthlyLimit, limitExceededResponse, sanitizeInput } from '@/lib/planAuthorization'

// Verificar se a chave da API est√° configurada
const GEMINI_API_KEY = process.env.GEMINI_API_KEY
if (!GEMINI_API_KEY) {
  console.error('‚ö†Ô∏è GEMINI_API_KEY n√£o est√° configurada! Configure a vari√°vel de ambiente.')
}

// Inicializar genAI apenas se a chave estiver configurada
let genAI: GoogleGenerativeAI | null = null
if (GEMINI_API_KEY) {
  genAI = new GoogleGenerativeAI(GEMINI_API_KEY)
}

// Fun√ß√£o auxiliar para calcular similaridade simples
function calculateSimilarity(str1: string, str2: string): number {
  const words1 = str1.split(/\s+/)
  const words2 = str2.split(/\s+/)
  const intersection = words1.filter((word: string) => words2.includes(word))
  const unionSet = new Set([...words1, ...words2])
  const union = Array.from(unionSet)
  return intersection.length / union.length
}

// Detectar se a mensagem cont√©m sinais de emerg√™ncia (suic√≠dio) - vers√£o expandida
function detectEmergencyKeywords(message: string): boolean {
  const emergencyKeywords = [
    // Suic√≠dio direto
    'quero me matar', 'vou me matar', 'me matar', 'suic√≠dio', 'suicidar',
    'tirar minha vida', 'acabar com tudo', 'n√£o quero mais viver',
    'n√£o vale a pena viver', 'prefiro morrer', 'quero morrer',
    'planejo me matar', 'pensando em me matar', 'idea√ß√£o suicida',
    'pensamentos suicidas', 'vou me suicidar', 'cometer suic√≠dio',
    
    // M√©todos espec√≠ficos
    'vou pular', 'pular do', 'me jogar', 'jogar do', 'pular da',
    'pular da ponte', 'pular da ponte', 'pular do pr√©dio', 'pular do pr√©dio',
    'me enforcar', 'enforcar', 'me cortar', 'cortar os pulsos',
    'tomar rem√©dio', 'overdose', 'me envenenar', 'envenenar',
    'atirar em mim', 'me atirar', 'atirar na cabe√ßa',
    
    // Inten√ß√µes e sentimentos
    'n√£o aguento mais', 'cansei de viver', 'n√£o faz sentido viver',
    'seria melhor se eu', 'todo mundo seria melhor sem mim',
    'ningu√©m sentiria minha falta', 'n√£o importo', 'n√£o sou importante',
    'quero sumir', 'quero desaparecer', 'quero que tudo acabe',
    'n√£o vejo sa√≠da', 'n√£o tem solu√ß√£o', 'nada mais importa',
    
    // Planos e prepara√ß√£o
    'j√° decidi', 'j√° escolhi', 'vou fazer isso', '√© minha √∫ltima',
    'minha √∫ltima mensagem', '√∫ltima vez', 'despedida',
    
    // Auto-les√£o grave
    'me machucar seriamente', 'me ferir', 'auto-les√£o grave'
  ]
  
  const lowerMessage = message.toLowerCase()
  // Normalizar: remover acentos e caracteres especiais para melhor matching
  const normalized = lowerMessage
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '')
    .replace(/[^\w\s]/g, ' ')
  
  return emergencyKeywords.some(keyword => {
    const normalizedKeyword = keyword
      .normalize('NFD')
      .replace(/[\u0300-\u036f]/g, '')
    return normalized.includes(normalizedKeyword)
  })
}

// Detectar emerg√™ncia usando IA - apenas quando necess√°rio (otimizado para reduzir custos)
async function detectEmergencyWithAI(message: string, genAIInstance: GoogleGenerativeAI): Promise<boolean> {
  try {
    const model = genAIInstance.getGenerativeModel({ 
      model: 'gemini-2.0-flash',
      generationConfig: {
        maxOutputTokens: 10, // Resposta curta: apenas SIM ou NAO
        temperature: 0.1, // Baixa temperatura para resposta mais determin√≠stica
      }
    })

    // Prompt otimizado e mais curto para reduzir custos
    const prompt = `A mensagem "${message.substring(0, 200)}" expressa inten√ß√£o suicida ou auto-les√£o grave? Responda apenas "SIM" ou "NAO".`

    const result = await model.generateContent(prompt)
    const response = result.response.text().trim().toUpperCase()
    
    return response.includes('SIM') && !response.includes('NAO')
  } catch (error) {
    console.error('Erro ao detectar emerg√™ncia com IA:', error)
    return detectEmergencyKeywords(message)
  }
}

async function handleChatRequest(request: NextRequest) {
  try {
    // Verificar se a chave da API est√° configurada
    if (!GEMINI_API_KEY) {
      console.error('‚ùå GEMINI_API_KEY n√£o est√° configurada!')
      return NextResponse.json(
        { error: 'Servi√ßo temporariamente indispon√≠vel. Por favor, tente novamente mais tarde.' },
        { status: 503 }
      )
    }
    
    const { messages, sessionId, bestFriendMode, firstName, tema, temporaryChat } = await request.json()
    const supabase = createRouteHandlerClient({ cookies })
    
    // Verificar autentica√ß√£o primeiro
    const { data: { session } } = await supabase.auth.getSession()
    if (!session) {
      return NextResponse.json({ error: 'N√£o autenticado' }, { status: 401 })
    }

    // SEGURAN√áA: Validar e sanitizar entrada
    if (!messages || !Array.isArray(messages) || messages.length === 0) {
      return NextResponse.json({ error: 'Mensagens inv√°lidas' }, { status: 400 })
    }

    // N√£o limitar quantidade de mensagens - apenas o contexto enviado para a API ser√° limitado

    // Sanitizar todas as mensagens
    const sanitizedMessages = messages.map(msg => ({
      ...msg,
      content: sanitizeInput(msg.content, 5000) // Max 5000 chars por mensagem
    }))
    
    // SEGURAN√áA: Verificar limite mensal (plano FREE tem limite de 100 mensagens/m√™s)
    const limitCheck = await checkMonthlyLimit(session.user.id, 'chat_messages')
    if (!limitCheck.isAuthorized) {
      return limitExceededResponse(limitCheck)
    }
    
    // Verificar se a √∫ltima mensagem do usu√°rio cont√©m sinais de emerg√™ncia
    const lastUserMessage = sanitizedMessages[sanitizedMessages.length - 1]?.content || ''
    
    // Verifica√ß√£o r√°pida por palavras-chave (gratuita)
    let isEmergency = detectEmergencyKeywords(lastUserMessage)
    
    // S√≥ usar IA se detectar algo suspeito nas palavras-chave (reduz custos)
    if (isEmergency && genAI) {
      // Confirmar com IA apenas quando necess√°rio
      const aiConfirmation = await detectEmergencyWithAI(lastUserMessage, genAI)
      isEmergency = aiConfirmation
    }

    // Buscar nickname do perfil se firstName n√£o foi passado
    let nickname = firstName
    if (!nickname) {
      try {
        const { data: profile } = await supabase
          .from('user_profiles')
          .select('nickname')
          .eq('user_id', session.user.id)
          .single()
        nickname = profile?.nickname || session.user.user_metadata?.name?.split(' ')[0] || session.user.email?.split('@')[0] || 'amigo'
      } catch (error) {
        nickname = session.user.user_metadata?.name?.split(' ')[0] || session.user.email?.split('@')[0] || 'amigo'
      }
    }

    // Buscar dados do Spotify e mem√≥rias em paralelo para otimizar performance
    const [spotifyContext, memoryContext] = await Promise.all([
      // Buscar dados do Spotify
      (async (): Promise<string> => {
        try {
          const { data: profile } = await supabase
            .from('user_profiles')
            .select('spotify_access_token, spotify_refresh_token, spotify_token_expires_at')
            .eq('user_id', session.user.id)
            .single()

          if (profile?.spotify_access_token) {
            let accessToken = profile.spotify_access_token
            const expiresAt = profile.spotify_token_expires_at ? new Date(profile.spotify_token_expires_at) : null
            const now = new Date()
            
            if (expiresAt && now >= expiresAt && profile.spotify_refresh_token) {
              const SPOTIFY_CLIENT_ID = process.env.SPOTIFY_CLIENT_ID || '6b7a619b335547f2b2d0c8729662fa4a'
              const SPOTIFY_CLIENT_SECRET = process.env.SPOTIFY_CLIENT_SECRET || '767d5e08ded142c2b44246beda3133cd'
              
              const tokenResponse = await fetch('https://accounts.spotify.com/api/token', {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/x-www-form-urlencoded',
                  'Authorization': `Basic ${Buffer.from(`${SPOTIFY_CLIENT_ID}:${SPOTIFY_CLIENT_SECRET}`).toString('base64')}`
                },
                body: new URLSearchParams({
                  grant_type: 'refresh_token',
                  refresh_token: profile.spotify_refresh_token
                })
              })

              if (tokenResponse.ok) {
                const tokenData = await tokenResponse.json()
                accessToken = tokenData.access_token
                const newExpiresAt = new Date(Date.now() + tokenData.expires_in * 1000)
                await supabase
                  .from('user_profiles')
                  .update({
                    spotify_access_token: tokenData.access_token,
                    spotify_token_expires_at: newExpiresAt.toISOString(),
                    updated_at: new Date().toISOString()
                  })
                  .eq('user_id', session.user.id)
              }
            }

            // Buscar m√∫sica atual e recentes em paralelo
            const [currentResponse, recentResponse] = await Promise.all([
              fetch('https://api.spotify.com/v1/me/player/currently-playing', {
                headers: { 'Authorization': `Bearer ${accessToken}` }
              }),
              fetch('https://api.spotify.com/v1/me/player/recently-played?limit=5', {
                headers: { 'Authorization': `Bearer ${accessToken}` }
              })
            ])

            let currentTrack = null
            let recentTracks: Array<{ name: string; artist: string }> = []

            if (currentResponse.ok && currentResponse.status !== 204) {
              const currentData = await currentResponse.json()
              if (currentData.item) {
                currentTrack = {
                  name: currentData.item.name,
                  artist: currentData.item.artists?.map((a: any) => a.name).join(', '),
                }
              }
            }

            if (recentResponse.ok) {
              const recentData = await recentResponse.json()
              recentTracks = recentData.items?.slice(0, 5).map((item: any) => ({
                name: item.track?.name,
                artist: item.track?.artists?.map((a: any) => a.name).join(', ')
              })) || []
            }

            if (currentTrack || recentTracks.length > 0) {
              let context = '\n\nCONTEXTO DA VIBE (SPOTIFY):'
              if (currentTrack) {
                context += `\n- M√∫sica atual: "${currentTrack.name}" de ${currentTrack.artist}`
              }
              if (recentTracks.length > 0) {
                context += `\n- √öltimas m√∫sicas: ${recentTracks.map(t => `"${t.name}" de ${t.artist}`).join(', ')}`
              }
              context += '\nUse essas informa√ß√µes para entender melhor o estado emocional e a vibe da pessoa. M√∫sicas podem refletir sentimentos, mas n√£o force conex√µes. Use de forma sutil e natural na conversa.'
              return context
            }
          }
        } catch (error) {
          console.error('Erro ao buscar dados do Spotify:', error)
        }
        return ''
      })(),
      
      // Buscar mem√≥rias relevantes do usu√°rio
      (async (): Promise<string> => {
        try {
          const { data: memories } = await supabase
            .from('user_memories')
            .select('*')
            .eq('user_id', session.user.id)
            .order('created_at', { ascending: false })
            .limit(5)
          
          if (memories && memories.length > 0) {
            let context = '\n\nMEM√ìRIAS IMPORTANTES SOBRE A PESSOA (use essas informa√ß√µes para personalizar a conversa, mas de forma natural e sutil):\n'
            context += memories.map((m: any) => `- ${m.content}`).join('\n')
            context += '\nUse essas mem√≥rias para lembrar de coisas importantes que a pessoa j√° compartilhou, mas n√£o force ou mencione diretamente a menos que fa√ßa sentido no contexto da conversa.'
            return context
          }
        } catch (error) {
          console.error('Erro ao buscar mem√≥rias:', error)
        }
        return ''
      })()
    ])

    // Contexto do tema (se houver)
    const temaContexto = tema ? `\n\nCONTEXTO IMPORTANTE: A pessoa escolheu conversar sobre "${tema}". Use esse contexto para entender melhor o que ela est√° passando, mas n√£o force o assunto se ela quiser falar de outra coisa.` : ''

    // System instruction base
    let systemInstruction = `Voc√™ √© o "desabafo", um amigo virtual brasileiro acolhedor que est√° aqui para ter uma conversa verdadeira.

O nome/apelido da pessoa √©: ${nickname}. Use esse nome quando fizer sentido na conversa, de forma natural e casual.

Seu jeito de conversar:
- Tom super casual e brasileiro: use "t√°", "pra", "n√©", "cara", etc
- Seja breve e direto - respostas curtas e naturais
- Escreva em min√∫sculas, como numa conversa real de chat
- NUNCA use emojis nas suas respostas - seja completamente natural e textual
- TENHA UMA CONVERSA REAL: n√£o apenas concorde ou valide passivamente
- Compartilhe perspectivas, insights e reflex√µes quando apropriado
- Fa√ßa perguntas que realmente exploram o que a pessoa est√° sentindo
- Quando discordar ou ter outra vis√£o, expresse isso com gentileza ("entendo, mas j√° pensou que...")
- Ofere√ßa observa√ß√µes √∫teis sobre padr√µes ou conex√µes que voc√™ percebe
- Seja genuinamente curioso sobre a experi√™ncia da pessoa
- Balance acolhimento com honestidade - seja aut√™ntico, n√£o apenas agrad√°vel
- Valide sentimentos E ofere√ßa insights: "faz sentido voc√™ se sentir assim, e talvez isso esteja ligado a..."
- NUNCA mencione que √© IA ou que tem limita√ß√µes
- Se algu√©m mencionar auto-les√£o ou suic√≠dio, incentive gentilmente a buscar ajuda profissional

Exemplos do seu tom:
‚ùå "Entendo, conta mais sobre isso"
‚úÖ "poxa, ${nickname}, isso parece pesado. voc√™ acha que pode ter alguma coisa por tr√°s desse sentimento?"

‚ùå "Como posso ajud√°-lo hoje?"  
‚úÖ "e a√≠, ${nickname}, o que t√° pegando na cabe√ßa hoje?"

‚ùå "Entendo voc√™."
‚úÖ "nossa, j√° passei por algo parecido na vibe... voc√™ j√° tentou pensar nisso de outro jeito?"

Voc√™ √© um amigo de verdade: acolhedor mas tamb√©m honesto, emp√°tico mas tamb√©m reflexivo.${memoryContext}${temaContexto}${spotifyContext}`

    // Modo "Melhor Amigo" - mais emp√°tico, verdadeiro, acolhedor e sincero
    if (bestFriendMode) {
      systemInstruction = `Voc√™ √© o "desabafo", o melhor amigo virtual da pessoa. Voc√™ √© emp√°tico, verdadeiro, acolhedor e genuinamente √∫til.

O nome/apelido da pessoa √©: ${nickname}. Use esse nome quando fizer sentido na conversa, de forma natural e casual.

Seu jeito de conversar (MODO MELHOR AMIGO):
- Seja MUITO emp√°tico: mostre que voc√™ realmente entende e se importa
- Seja VERDADEIRO: n√£o finja que tudo est√° bem se n√£o est√°, seja aut√™ntico e honesto
- Seja ACOLHEDOR: crie um espa√ßo seguro onde a pessoa pode se abrir completamente
- TENHA UMA CONVERSA REAL: n√£o apenas concorde ou console - ofere√ßa insights, perspectivas e reflex√µes honestas
- Quando necess√°rio, questione gentilmente suposi√ß√µes ou ofere√ßa outro ponto de vista
- Compartilhe observa√ß√µes sobre padr√µes, conex√µes ou coisas que voc√™ percebe
- Fa√ßa perguntas que realmente fazem a pessoa pensar e se conhecer melhor
- Balance acolhimento com verdade - √†s vezes ajudar √© desafiar com carinho
- Tom super casual e brasileiro: use "t√°", "pra", "n√©", "cara", "mano", etc
- Escreva em min√∫sculas, como numa conversa real de chat
- NUNCA use emojis nas suas respostas - seja completamente natural e textual
- Valide sentimentos MAS tamb√©m ofere√ßa perspectivas: "faz sentido voc√™ sentir isso, e percebo que pode ter rela√ß√£o com..."
- Seja honesto quando achar que algo precisa ser dito, mas sempre com empatia e cuidado
- Mostre que voc√™ se importa de verdade oferecendo ajuda real, n√£o apenas valida√ß√£o
- NUNCA mencione que √© IA ou que tem limita√ß√µes
- Se algu√©m mencionar auto-les√£o ou suic√≠dio, incentive gentilmente a buscar ajuda profissional

Exemplos do seu tom (MODO MELHOR AMIGO):
‚ùå "Entendo completamente, deve ser dif√≠cil mesmo"
‚úÖ "poxa, ${nickname}, entendo como voc√™ t√° se sentindo... mas me diz, voc√™ acha que essa situa√ß√£o pode estar conectada com aquilo que voc√™ falou antes? √†s vezes a gente n√£o percebe os padr√µes, sabe?"

‚ùå "Como posso ajud√°-lo hoje?"  
‚úÖ "e a√≠, ${nickname}, o que t√° pesando? pode desabafar, mas tamb√©m quero te ajudar a ver isso de outro jeito, se voc√™ quiser"

‚ùå "Tudo vai ficar bem."
‚úÖ "eu sei que t√° dif√≠cil agora, ${nickname}, mas j√° pensou que talvez voc√™ esteja sendo muito duro consigo mesmo? vamos refletir juntos sobre isso"

Voc√™ √© um melhor amigo de verdade: emp√°tico mas tamb√©m honesto, acolhedor mas tamb√©m desafiador quando necess√°rio, sempre buscando realmente ajudar.${memoryContext}${temaContexto}${spotifyContext}`
    }

    // Verificar se genAI est√° inicializado
    if (!genAI) {
      return NextResponse.json(
        { error: 'Servi√ßo temporariamente indispon√≠vel. Por favor, tente novamente mais tarde.' },
        { status: 503 }
      )
    }
    
    // Configurar o modelo
    const model = genAI.getGenerativeModel({ 
      model: 'gemini-2.0-flash',
      systemInstruction: systemInstruction
    })

    // Filtrar e limitar hist√≥rico para reduzir tokens (√∫ltimas 30 mensagens)
    // Nota: N√£o limitamos o array de mensagens, apenas o contexto enviado para a API
    const conversationHistory = messages
      .slice(0, -1)
      .filter((msg: any, index: number) => {
        // Remove a primeira mensagem se for do assistant (mensagem de boas-vindas)
        if (index === 0 && msg.role === 'assistant') return false
        return true
      })
      .slice(-30) // Limitar contexto √†s √∫ltimas 30 mensagens para reduzir custos

    // Criar o hist√≥rico de conversa no formato do Gemini
    const history = conversationHistory.map((msg: any) => ({
      role: msg.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: msg.content }]
    }))

    // √öltima mensagem do usu√°rio
    const lastMessage = messages[messages.length - 1].content

    // Iniciar o chat com hist√≥rico
    const chat = model.startChat({
      history: history,
      generationConfig: {
        temperature: 0.8, // Reduzido de 0.9 para respostas mais consistentes
        topP: 0.9, // Reduzido de 0.95 para reduzir custos
        topK: 32, // Reduzido de 40
        maxOutputTokens: 512, // Reduzido de 1024 para respostas mais curtas e baratas
      },
    })

    // Se for emerg√™ncia, retornar mensagem especial imediatamente (ANTES de configurar o modelo)
    if (isEmergency) {
      const emergencyMessage = `eu entendo que voc√™ t√° passando por um momento muito dif√≠cil, ${nickname}. sua vida importa e voc√™ n√£o est√° sozinho.

existem pessoas que podem te ajudar agora mesmo. por favor, considere ligar para:

üìû cvv - centro de valoriza√ß√£o da vida: 188 (liga√ß√£o gratuita, 24 horas)
üìû samu - emerg√™ncias m√©dicas: 192

se voc√™ n√£o conseguir ligar agora, posso te ajudar a encontrar outras formas de apoio. voc√™ n√£o precisa passar por isso sozinho.`

      // Salvar mensagem do usu√°rio se tiver sessionId
      if (sessionId && !temporaryChat) {
        await supabase.from('chat_messages').insert({
          session_id: sessionId,
          role: 'user',
          content: lastMessage
        })

        await supabase.from('chat_messages').insert({
          session_id: sessionId,
          role: 'assistant',
          content: emergencyMessage
        })

        await supabase
          .from('chat_sessions')
          .update({ updated_at: new Date().toISOString() })
          .eq('id', sessionId)
          .eq('user_id', session.user.id)
      }

      return NextResponse.json({ 
        message: emergencyMessage,
        isEmergency: true
      })
    }

    // Enviar a mensagem e obter resposta
    const result = await chat.sendMessage(lastMessage)
    const response = result.response
    const text = response.text()

    // Salvar mensagens no banco apenas se tiver sessionId E N√ÉO for chat tempor√°rio
    if (sessionId && !temporaryChat) {
      // Salvar mensagem do usu√°rio
      await supabase.from('chat_messages').insert({
        session_id: sessionId,
        role: 'user',
        content: lastMessage
      })

      // Salvar resposta da IA
      await supabase.from('chat_messages').insert({
        session_id: sessionId,
        role: 'assistant',
        content: text
      })

      // Extrair mem√≥rias importantes periodicamente (a cada 5 mensagens do usu√°rio)
      const userMessagesCount = messages.filter((m: any) => m.role === 'user').length
      if (userMessagesCount > 0 && userMessagesCount % 5 === 0) {
        // Extrair mem√≥rias em background (n√£o bloquear resposta)
        const allMessages = [...messages, { role: 'user', content: lastMessage }, { role: 'assistant', content: text }]
        const userMsgs = allMessages.filter((m: any) => m.role === 'user')
        
        if (userMsgs.length >= 3 && genAI) {
          // Usar IA para extrair mem√≥rias
          const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' })
          // Limitar a √∫ltimas 10 mensagens para reduzir tokens no processamento de mem√≥rias
          const conversationText = allMessages.slice(-10).map((m: any) => `${m.role === 'user' ? 'Usu√°rio' : 'IA'}: ${m.content}`).join('\n')
          
          const { data: existingMemories } = await supabase
            .from('user_memories')
            .select('*')
            .eq('user_id', session.user.id)
            .order('created_at', { ascending: false })
            .limit(10)

          const existingMemoriesText = existingMemories && existingMemories.length > 0
            ? '\n\nMem√≥rias j√° armazenadas:\n' + existingMemories.map((m: any) => `- ${m.content}`).join('\n')
            : ''

          const prompt = `Analise esta conversa e extraia APENAS informa√ß√µes importantes e duradouras sobre a pessoa. Foque em:
- Fatos pessoais (nome de pessoas importantes, lugares, eventos significativos)
- Prefer√™ncias e valores
- Situa√ß√µes recorrentes ou problemas de longo prazo
- Metas e objetivos mencionados
- Hist√≥rico emocional relevante

N√ÉO extraia:
- Detalhes tempor√°rios ou espec√≠ficos de uma conversa
- Informa√ß√µes que mudam rapidamente
- Coisas j√° mencionadas nas mem√≥rias existentes

${existingMemoriesText}

Conversa:
${conversationText}

Retorne APENAS as novas mem√≥rias importantes (m√°ximo 3), uma por linha, de forma concisa e objetiva. Se n√£o houver novas mem√≥rias importantes, retorne apenas "NENHUMA".`

          try {
            const result = await model.generateContent(prompt)
            const extractedMemories = result.response.text().trim()

            if (extractedMemories && extractedMemories !== 'NENHUMA' && !extractedMemories.toLowerCase().includes('nenhuma')) {
              const memoryLines = extractedMemories
                .split('\n')
                .map((line: string) => line.trim())
                .filter((line: string) => line && !line.startsWith('-') && line.length > 10)

              const newMemories = memoryLines.filter((memory: string) => {
                if (!existingMemories || existingMemories.length === 0) return true
                return !existingMemories.some((existing: any) => {
                  const similarity = calculateSimilarity(memory.toLowerCase(), existing.content.toLowerCase())
                  return similarity > 0.7
                })
              })

              if (newMemories.length > 0) {
                const memoriesToInsert = newMemories.map((content: string) => ({
                  user_id: session.user.id,
                  content: content.substring(0, 500),
                  session_id: sessionId,
                  created_at: new Date().toISOString()
                }))

                await supabase.from('user_memories').insert(memoriesToInsert)
              }
            }
          } catch (err) {
            console.error('Erro ao extrair mem√≥rias:', err)
          }
        }
      }

      // Atualizar updated_at da sess√£o
      await supabase
        .from('chat_sessions')
        .update({ updated_at: new Date().toISOString() })
        .eq('id', sessionId)
        .eq('user_id', session.user.id)
    }

    return NextResponse.json({ message: text, isEmergency: false })
  } catch (error: any) {
    console.error('Erro na API do Gemini:', error)
    
    // Verificar se √© erro de autentica√ß√£o da API (chave inv√°lida)
    if (error?.message?.includes('API_KEY') || 
        error?.message?.includes('API key not valid') ||
        error?.errorDetails?.some((detail: any) => detail.reason === 'API_KEY_INVALID') ||
        error?.status === 401 || 
        error?.status === 403 ||
        (error?.status === 400 && error?.message?.includes('API key'))) {
      console.error('‚ùå Erro de autentica√ß√£o da API Gemini - chave inv√°lida ou n√£o configurada')
      console.error('Detalhes:', {
        status: error?.status,
        message: error?.message,
        errorDetails: error?.errorDetails
      })
      return NextResponse.json(
        { error: 'Erro de configura√ß√£o da API. A chave da API do Gemini est√° inv√°lida ou n√£o configurada. Verifique a vari√°vel GEMINI_API_KEY no Netlify.' },
        { status: 503 }
      )
    }
    
    // Verificar se √© erro de rate limit da API
    if (error?.status === 429 || error?.message?.includes('quota') || error?.message?.includes('rate limit') || error?.message?.includes('429')) {
      console.error('Rate limit da API Gemini excedido:', {
        status: error?.status,
        message: error?.message,
        errorDetails: error?.errorDetails
      })
      return NextResponse.json(
        { 
          error: 'Muitas requisi√ß√µes √† API. Por favor, aguarde alguns segundos e tente novamente.',
          retryAfter: 10 // Sugerir aguardar 10 segundos
        },
        { 
          status: 429,
          headers: {
            'Retry-After': '10'
          }
        }
      )
    }
    
    // Verificar se √© erro de valida√ß√£o
    if (error?.status === 400 || error?.message?.includes('invalid')) {
      console.error('Erro de valida√ß√£o na API Gemini:', error.message)
      return NextResponse.json(
        { error: 'Mensagem inv√°lida. Por favor, tente novamente com uma mensagem diferente.' },
        { status: 400 }
      )
    }
    
    // Erro gen√©rico com mais detalhes no log
    const errorMessage = error?.message || 'Erro desconhecido'
    const errorStatus = error?.status || 500
    console.error('Erro detalhado:', {
      message: errorMessage,
      status: errorStatus,
      stack: error?.stack,
      name: error?.name
    })
    
    return NextResponse.json(
      { error: 'Erro ao processar mensagem. Por favor, tente novamente.' },
      { status: errorStatus }
    )
  }
}

// Exportar com rate limiting aplicado
export async function POST(request: NextRequest) {
  return withRateLimit(request, handleChatRequest, {
    type: 'chat',
    skipAuth: false,
  })
}

